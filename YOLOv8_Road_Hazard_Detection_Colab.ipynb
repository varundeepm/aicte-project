{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöó YOLOv8 Road Hazard Detection - Complete Colab Notebook\n",
    "## AICTE Project: AI-Powered Road Monitoring System\n",
    "\n",
    "**This notebook trains a YOLOv8 model to detect 8 types of road hazards:**\n",
    "1. Pothole\n",
    "2. Crack\n",
    "3. Debris\n",
    "4. Waterlogging\n",
    "5. Damaged Sign\n",
    "6. Vegetation Overgrowth\n",
    "7. Construction\n",
    "8. Accident Site\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q ultralytics roboflow\n",
    "!pip install -q opencv-python-headless\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import yaml\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üì¶ Ultralytics YOLO version: {YOLO.__version__ if hasattr(YOLO, '__version__') else 'Latest'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Upload Your Dataset\n",
    "\n",
    "**Option A:** Upload your own labeled dataset (YOLO format)  \n",
    "**Option B:** Use sample/demo dataset from Roboflow  \n",
    "**Option C:** Download public road damage datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Upload Your Own Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset ZIP file\n",
    "# Dataset should be in YOLO format:\n",
    "# dataset.zip/\n",
    "#   ‚îú‚îÄ‚îÄ images/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "#   ‚îú‚îÄ‚îÄ labels/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "#   ‚îî‚îÄ‚îÄ data.yaml\n",
    "\n",
    "print(\"üì§ Upload your dataset ZIP file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract ZIP\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('dataset')\n",
    "    print(f\"‚úÖ Extracted to 'dataset' folder\")\n",
    "\n",
    "# List contents\n",
    "!ls -lh dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Use Roboflow Dataset (Recommended for Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a public road damage dataset from Roboflow\n",
    "# Sign up at https://roboflow.com and get your API key\n",
    "\n",
    "# Example: Pothole detection dataset\n",
    "# !pip install roboflow\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "# project = rf.workspace(\"YOUR_WORKSPACE\").project(\"YOUR_PROJECT\")\n",
    "# dataset = project.version(1).download(\"yolov8\")\n",
    "\n",
    "print(\"‚ÑπÔ∏è If using Roboflow, uncomment and add your API key above\")\n",
    "print(\"‚ÑπÔ∏è Or use Option C to download public datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Download Public Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download RDD2020 (Road Damage Dataset)\n",
    "# This is a sample - replace with actual dataset URL\n",
    "\n",
    "# Example: Download from Kaggle (requires Kaggle API key)\n",
    "# !pip install kaggle\n",
    "# !kaggle datasets download -d atulyakumar98/pothole-detection-dataset\n",
    "# !unzip pothole-detection-dataset.zip -d dataset/\n",
    "\n",
    "print(\"‚ÑπÔ∏è For Kaggle datasets:\")\n",
    "print(\"1. Go to https://www.kaggle.com/settings\")\n",
    "print(\"2. Create API token\")\n",
    "print(\"3. Upload kaggle.json to Colab\")\n",
    "print(\"4. Run: !mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 3: Create Dataset Configuration\n",
    "\n",
    "Create `data.yaml` if not included in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml configuration\n",
    "data_yaml = {\n",
    "    'path': '/content/dataset',  # dataset root dir\n",
    "    'train': 'images/train',  # train images\n",
    "    'val': 'images/val',  # val images\n",
    "    'test': 'images/test',  # test images (optional)\n",
    "    \n",
    "    'names': {\n",
    "        0: 'pothole',\n",
    "        1: 'crack',\n",
    "        2: 'debris',\n",
    "        3: 'waterlogging',\n",
    "        4: 'damaged_sign',\n",
    "        5: 'vegetation_overgrowth',\n",
    "        6: 'construction',\n",
    "        7: 'accident_site'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('/content/dataset/data.yaml', 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ data.yaml created!\")\n",
    "print(\"\\nConfiguration:\")\n",
    "!cat /content/dataset/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "import os\n",
    "\n",
    "dataset_path = '/content/dataset'\n",
    "\n",
    "# Count images and labels\n",
    "def count_files(path, extension):\n",
    "    return len([f for f in os.listdir(path) if f.endswith(extension)]) if os.path.exists(path) else 0\n",
    "\n",
    "print(\"üìä Dataset Statistics:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_path = os.path.join(dataset_path, 'images', split)\n",
    "    lbl_path = os.path.join(dataset_path, 'labels', split)\n",
    "    \n",
    "    n_images = count_files(img_path, ('.jpg', '.jpeg', '.png'))\n",
    "    n_labels = count_files(lbl_path, '.txt')\n",
    "    \n",
    "    print(f\"{split.upper():>8} set: {n_images:>5} images, {n_labels:>5} labels\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with labels\n",
    "import random\n",
    "\n",
    "def show_sample_images(n_samples=6):\n",
    "    img_dir = '/content/dataset/images/train'\n",
    "    lbl_dir = '/content/dataset/labels/train'\n",
    "    \n",
    "    if not os.path.exists(img_dir):\n",
    "        print(\"‚ö†Ô∏è No training images found!\")\n",
    "        return\n",
    "    \n",
    "    images = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    samples = random.sample(images, min(n_samples, len(images)))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    class_names = list(data_yaml['names'].values())\n",
    "    \n",
    "    for idx, img_name in enumerate(samples):\n",
    "        # Read image\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read labels\n",
    "        lbl_path = os.path.join(lbl_dir, img_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "        \n",
    "        if os.path.exists(lbl_path):\n",
    "            with open(lbl_path, 'r') as f:\n",
    "                labels = f.readlines()\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            h, w = img.shape[:2]\n",
    "            for label in labels:\n",
    "                parts = label.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    cls_id = int(parts[0])\n",
    "                    x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    x1 = int((x_center - width/2) * w)\n",
    "                    y1 = int((y_center - height/2) * h)\n",
    "                    x2 = int((x_center + width/2) * w)\n",
    "                    y2 = int((y_center + height/2) * h)\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    \n",
    "                    # Add label\n",
    "                    label_text = class_names[cls_id] if cls_id < len(class_names) else f\"Class {cls_id}\"\n",
    "                    cv2.putText(img, label_text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(img_name, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"‚úÖ Sample images with annotations displayed\")\n",
    "\n",
    "show_sample_images(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Train YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8 model\n",
    "# Options: yolov8n.pt (nano - fastest), yolov8s.pt (small), yolov8m.pt (medium), yolov8l.pt (large), yolov8x.pt (extra large)\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # Start with nano for faster training\n",
    "\n",
    "print(\"‚úÖ YOLOv8 model loaded!\")\n",
    "print(f\"   Model: yolov8n.pt (nano - optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"Training Configuration:\")\n",
    "print(\"  ‚Ä¢ Model: YOLOv8n (nano)\")\n",
    "print(\"  ‚Ä¢ Epochs: 50\")\n",
    "print(\"  ‚Ä¢ Image Size: 640x640\")\n",
    "print(\"  ‚Ä¢ Batch Size: 16\")\n",
    "print(\"  ‚Ä¢ Device: GPU (if available)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "results = model.train(\n",
    "    data='/content/dataset/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='road_hazard_detection',\n",
    "    project='runs/detect',\n",
    "    patience=10,  # Early stopping\n",
    "    save=True,\n",
    "    plots=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 6: View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "import glob\n",
    "\n",
    "print(\"üìä Training Results:\\n\")\n",
    "\n",
    "# Find the latest training run\n",
    "run_dir = 'runs/detect/road_hazard_detection'\n",
    "\n",
    "if os.path.exists(run_dir):\n",
    "    # Display results\n",
    "    result_img = os.path.join(run_dir, 'results.png')\n",
    "    if os.path.exists(result_img):\n",
    "        print(\"Training Curves:\")\n",
    "        display(Image(filename=result_img))\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    conf_matrix = os.path.join(run_dir, 'confusion_matrix.png')\n",
    "    if os.path.exists(conf_matrix):\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        display(Image(filename=conf_matrix))\n",
    "    \n",
    "    # Display sample predictions\n",
    "    val_batch = os.path.join(run_dir, 'val_batch0_pred.jpg')\n",
    "    if os.path.exists(val_batch):\n",
    "        print(\"\\nSample Predictions:\")\n",
    "        display(Image(filename=val_batch))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 7: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = 'runs/detect/road_hazard_detection/weights/best.pt'\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "print(\"‚úÖ Best model loaded!\")\n",
    "print(f\"   Path: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"üß™ Evaluating on validation set...\\n\")\n",
    "\n",
    "metrics = best_model.val()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"mAP@0.5:       {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95:  {metrics.box.map:.4f}\")\n",
    "print(f\"Precision:     {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall:        {metrics.box.mr:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 8: Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test images\n",
    "print(\"üì§ Upload test images to detect road hazards...\")\n",
    "test_images = files.upload()\n",
    "\n",
    "print(f\"\\n‚úÖ Uploaded {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test images\n",
    "fig, axes = plt.subplots(len(test_images), 1, figsize=(12, 6*len(test_images)))\n",
    "\n",
    "if len(test_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (filename, _) in enumerate(test_images.items()):\n",
    "    # Run detection\n",
    "    results = best_model(filename, conf=0.5)\n",
    "    \n",
    "    # Get annotated image\n",
    "    annotated_img = results[0].plot()\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display\n",
    "    axes[idx].imshow(annotated_img)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Detection Results: {filename}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Print detections\n",
    "    print(f\"\\nüìä Detections for {filename}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    boxes = results[0].boxes\n",
    "    if len(boxes) > 0:\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = data_yaml['names'][cls_id]\n",
    "            print(f\"  ‚Ä¢ {cls_name}: {conf:.2%} confidence\")\n",
    "    else:\n",
    "        print(\"  No hazards detected\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Inference completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "print(\"üì¶ Exporting model to various formats...\\n\")\n",
    "\n",
    "# Export to ONNX (for deployment)\n",
    "best_model.export(format='onnx')\n",
    "print(\"‚úÖ Exported to ONNX format\")\n",
    "\n",
    "# Export to TorchScript\n",
    "best_model.export(format='torchscript')\n",
    "print(\"‚úÖ Exported to TorchScript format\")\n",
    "\n",
    "print(\"\\nüìÅ Exported models are in: runs/detect/road_hazard_detection/weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained model\n",
    "print(\"üì• Downloading trained model...\\n\")\n",
    "\n",
    "# Zip the weights folder\n",
    "!zip -r trained_model.zip runs/detect/road_hazard_detection/weights/\n",
    "\n",
    "print(\"\\n‚úÖ Model packaged!\")\n",
    "print(\"\\nDownload 'trained_model.zip' to use in your deployment:\")\n",
    "\n",
    "files.download('trained_model.zip')\n",
    "\n",
    "print(\"\\nüìå Usage in deployment:\")\n",
    "print(\"   python yolov8_realtime_detection.py --model path/to/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 10: Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training report\n",
    "print(\"=\"*70)\n",
    "print(\"üìä TRAINING REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüéØ Model Configuration:\")\n",
    "print(f\"   Model Architecture: YOLOv8n (nano)\")\n",
    "print(f\"   Number of Classes: 8\")\n",
    "print(f\"   Classes: {', '.join(data_yaml['names'].values())}\")\n",
    "print(f\"   Image Size: 640x640\")\n",
    "print(f\"   Epochs: 50\")\n",
    "print(f\"   Batch Size: 16\")\n",
    "\n",
    "print(\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   mAP@0.5:       {metrics.box.map50:.4f} ({metrics.box.map50*100:.2f}%)\")\n",
    "print(f\"   mAP@0.5:0.95:  {metrics.box.map:.4f} ({metrics.box.map*100:.2f}%)\")\n",
    "print(f\"   Precision:     {metrics.box.mp:.4f}\")\n",
    "print(f\"   Recall:        {metrics.box.mr:.4f}\")\n",
    "\n",
    "print(\"\\nüìÅ Model Files:\")\n",
    "print(f\"   Best Weights: runs/detect/road_hazard_detection/weights/best.pt\")\n",
    "print(f\"   Last Weights: runs/detect/road_hazard_detection/weights/last.pt\")\n",
    "\n",
    "print(\"\\nüöÄ Deployment:\")\n",
    "print(\"   1. Download trained_model.zip\")\n",
    "print(\"   2. Extract best.pt\")\n",
    "print(\"   3. Use with: python yolov8_realtime_detection.py --model best.pt\")\n",
    "\n",
    "print(\"\\n‚úÖ Training Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Next Steps\n",
    "\n",
    "1. **Download the trained model** (`trained_model.zip`)\n",
    "2. **Extract** `best.pt` from the zip file\n",
    "3. **Deploy** using the project scripts:\n",
    "   ```bash\n",
    "   python yolov8_realtime_detection.py --model best.pt --camera 0\n",
    "   ```\n",
    "4. **Integrate** with full system:\n",
    "   ```bash\n",
    "   python integrated_deployment.py --model best.pt\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **YOLOv8 Documentation:** https://docs.ultralytics.com\n",
    "- **Dataset Labeling:** Use LabelImg or Roboflow\n",
    "- **Public Datasets:**\n",
    "  - RDD2020: https://github.com/sekilab/RoadDamageDetector\n",
    "  - Pothole Detection: https://www.kaggle.com/datasets/atulyakumar98/pothole-detection-dataset\n",
    "\n",
    "---\n",
    "\n",
    "**Project Status: Model Training Complete ‚úÖ**\n",
    "\n",
    "All 4 AICTE objectives can now be demonstrated with this trained model!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
